{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPMENT_FILE = \"./dataset/development.csv\"\n",
    "EVALUATION_FILE = \"./dataset/evaluation.csv\"\n",
    "\n",
    "MALE_NAMES_FILE = \"./dataset/ITGivenMale.json\"\n",
    "FEMALE_NAMES_FILE = \"./dataset/ITGivenFemale.json\"\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "# Tokenization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Plot\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('it_core_news_sm', disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "spacy_tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print elapsed time\"\"\"\n",
    "def printElapsedTime(starting_time, task = ''):\n",
    "    m, s = divmod(time.time() - starting_time, 60)\n",
    "    task = ' - task: ' + task if task != '' else ''\n",
    "    print(f'Elapsed: {int(m):02d}:{int(s):02d}' + task)\n",
    "\n",
    "def getFeatures(data, tfidf, features = None, verbose=True):\n",
    "    \n",
    "    \"\"\"Feature selection\"\"\"\n",
    "    start_time = time.time()\n",
    "    # Dimensionality reduction using truncated SVD\n",
    "    if DIM_REDUCTION:\n",
    "        if DIM_REDUCTION == 'SVD':\n",
    "            svd = TruncatedSVD(n_components = 10000, n_iter = 10, random_state = 42)\n",
    "            tfidf = svd.fit_transform(tfidf)\n",
    "        elif DIM_REDUCTION == 'PCA':\n",
    "            from sklearn.decomposition import SparsePCA\n",
    "            pca = SparsePCA(n_components = 5000)\n",
    "            tfidf = pca.fit_transform(tfidf.toarray())\n",
    "    else:\n",
    "        tfidf = tfidf.toarray()\n",
    "    \n",
    "    if verbose:\n",
    "        printElapsedTime(start_time, 'dim reduction: ' + str(DIM_REDUCTION))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    X = pd.DataFrame(tfidf)\n",
    "    if verbose:\n",
    "        printElapsedTime(start_time, 'generate DataFrame')\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \"\"\"Text length\"\"\"\n",
    "    if TEXT_LENGTH:\n",
    "        X['text_len'] = features['text_len']\n",
    "    \n",
    "    \"\"\"Sentences count\"\"\"\n",
    "    if SENTENCES_CNT:\n",
    "        X['sentences_cnt'] = features['sentences_cnt']\n",
    "    \n",
    "    \"\"\"Person name\"\"\"\n",
    "    start_time = time.time() ## TIME\n",
    "    # Usually, on good reviews (and when they feel at home), people tend to write name of the staff\n",
    "    # Despite this initial idea, names tend to be more frequent on negative reviews\n",
    "    if FIRST_NAMES_CNT:\n",
    "        column = 'names_cnt'\n",
    "        X[column] = np.nan\n",
    "        column_loc = X.columns.get_loc(column)\n",
    "        \n",
    "        for i, text in enumerate(data['text']):\n",
    "            names_cnt = 0\n",
    "            for name in italian_firstnames:\n",
    "                if name in text:\n",
    "                    names_cnt += 1\n",
    "            X.iloc[i, column_loc] = names_cnt\n",
    "    \n",
    "    if verbose:\n",
    "        printElapsedTime(start_time, 'person names')\n",
    "    \n",
    "    \"\"\"Number of exclamation marks\"\"\"\n",
    "    if EXCLAMATION_MARKS_CNT:\n",
    "        X['exclam_mark_cnt'] = features['exclam_mark_cnt']\n",
    "    \n",
    "    \"\"\"Number of question marks\"\"\"\n",
    "    if QUESTION_MARKS_CNT:\n",
    "        X['question_mark_cnt'] = features['question_mark_cnt']\n",
    "    \n",
    "    \"\"\"Punctuation cnt\"\"\"\n",
    "    if PUNCTUATION_CNT:\n",
    "        X['punctuation_cnt'] = features['punctuation_cnt']\n",
    "    \n",
    "    \"\"\"Number of words types\"\"\"\n",
    "    start_time = time.time() ## TIME\n",
    "    if WORD_TYPES_CNT:\n",
    "        word_types = ['PART', 'SCONJ', 'DET', 'PUNCT', 'INTJ', 'ADV', 'SYM', 'NOUN', 'PROPN', 'NUM', 'ADP', 'X', 'VERB', 'AUX', 'CONJ', 'SPACE', 'ADJ', 'PRON']\n",
    "\n",
    "        for word_type in word_types:\n",
    "            X['cnt_' + word_type] = 0\n",
    "\n",
    "        for i, text in enumerate(data['text']):\n",
    "            word_types_dict = {}\n",
    "            for word_type in word_types:\n",
    "                word_types_dict[word_type] = 0\n",
    "\n",
    "            doc = getNlpFromText(text)\n",
    "            tokens_number = 0\n",
    "            for token in doc:\n",
    "                word_types_dict[token.pos_] += 1\n",
    "                tokens_number += 1\n",
    "\n",
    "            for key, value in word_types_dict.items():\n",
    "                X.iloc[i, X.columns.get_loc('cnt_' + key)] = value / tokens_number\n",
    "    \n",
    "    if verbose:\n",
    "        printElapsedTime(start_time, 'number of word types')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    for word, initial in replace_before_lemmatization.items():\n",
    "        text = text.replace(word, initial)\n",
    "        \n",
    "    nlp_doc = getNlpFromText(text)\n",
    "    tokens = nlp_doc\n",
    "    tokens_withoud_punct = [str(token.lemma_).translate(str.maketrans('', '', string.punctuation+' ')) for token in tokens]\n",
    "    return tokens_withoud_punct\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = spacy_tokenizer(text)\n",
    "    return list(map(str, tokens))\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "def regTokenizer(text):\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = WORD.findall(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp_documents\n",
    "    print(\"nlp_documents is already initialized\")\n",
    "except NameError:\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        with open('./cache/nlp_documents.p', 'rb') as fp:\n",
    "            nlp_documents = pickle.load(fp)\n",
    "        printElapsedTime(start_time, 'load nlp documents')\n",
    "    except:\n",
    "        nlp_documents = {}\n",
    "        print(\"nlp_documents.p not found\")\n",
    "\n",
    "def getNlpFromText(text):\n",
    "    if text in nlp_documents:\n",
    "        return nlp_documents[text]\n",
    "    else:\n",
    "        doc = nlp(text)\n",
    "        nlp_documents[text] = doc\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italian names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load Italian names\n",
    "with open(MALE_NAMES_FILE, 'r') as f:\n",
    "    data_male_names = json.load(f)\n",
    "with open(FEMALE_NAMES_FILE, 'r') as f:\n",
    "    data_female_names = json.load(f)\n",
    "male_names = list(map(lambda x: x['name'].lower(), data_male_names))\n",
    "female_names = list(map(lambda x: x['name'].lower(), data_female_names))\n",
    "italian_firstnames = male_names + female_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given data\"\"\"\n",
    "development_data = pd.read_csv(DEVELOPMENT_FILE)\n",
    "evaluation_data = pd.read_csv(EVALUATION_FILE)\n",
    "\n",
    "\"\"\"External data\"\"\"\n",
    "# Use data from external datasets\n",
    "USE_EXTERNAL_DATA = True\n",
    "\n",
    "# If USE_EXTERNAL_DATA, the original proportion between positive and negative has to be maintained?\n",
    "MAINTAIN_PROPORTION = True\n",
    "\n",
    "# 50% pos, 50% neg\n",
    "BALANCE_REVIEWS_PERFECTLY = False\n",
    "\n",
    "if USE_EXTERNAL_DATA:\n",
    "    external_data = pd.read_csv('./dataset/external_reviews.csv') # 50% pos, 50% neg\n",
    "    dev_pos_prop = development_data[development_data['class'] == 'pos'].shape[0] / development_data.shape[0]\n",
    "    dev_neg_prop = development_data[development_data['class'] == 'neg'].shape[0] / development_data.shape[0]\n",
    "    \n",
    "    external_pos = external_data[(external_data['label'] == 50) | (external_data['label'] == 40)]\n",
    "    external_pos = external_pos.drop(columns=['label'])\n",
    "    external_pos = external_pos.rename(columns={'review':'text'})\n",
    "    external_pos['class'] = 'pos'\n",
    "    \n",
    "    external_neg = external_data[(external_data['label'] == 10) | (external_data['label'] == 20)]\n",
    "    external_neg = external_neg.drop(columns=['label'])\n",
    "    external_neg = external_neg.rename(columns={'review':'text'})\n",
    "    external_neg['class'] = 'neg'\n",
    "    \n",
    "    # I should only add negative reviews such that the proportion is maintained\n",
    "    if MAINTAIN_PROPORTION:\n",
    "        neg_to_add = int((dev_neg_prop / dev_pos_prop) * len(external_neg))\n",
    "    else:\n",
    "        neg_to_add = len(external_neg)\n",
    "    \n",
    "    development_data = pd.concat([development_data, external_neg.sample(n=neg_to_add), external_pos],ignore_index=True).sample(frac=1)\n",
    "\n",
    "if BALANCE_REVIEWS_PERFECTLY:\n",
    "    neg_reviews = development_data[development_data['class'] == 'neg'].sample(frac=1)\n",
    "    pos_reviews = development_data[development_data['class'] == 'pos'].sample(frac=1)\n",
    "    \n",
    "    min_len = min(neg_reviews.shape[0], pos_reviews.shape[0])\n",
    "    neg_reviews = neg_reviews[:min_len]\n",
    "    pos_reviews = pos_reviews[:min_len]\n",
    "    \n",
    "    development_data = pd.concat([neg_reviews,pos_reviews],ignore_index=True).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalize = ['text_len', 'exclam_mark_cnt', 'question_mark_cnt', 'punctuation_cnt']\n",
    "features = {\n",
    "    'development': {\n",
    "        feature: [] for feature in features_to_normalize\n",
    "    },\n",
    "    'evaluation': {\n",
    "        feature: [] for feature in features_to_normalize\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "for text in development_data['text']:\n",
    "    features['development']['text_len'].append(len(text))\n",
    "    features['development']['exclam_mark_cnt'].append(text.count(\"!\"))\n",
    "    features['development']['question_mark_cnt'].append(text.count(\"?\"))\n",
    "    features['development']['punctuation_cnt'].append(len([char for char in text if char in punctuation]))\n",
    "    features['development']['sentences_cnt'].append(len(list(getNlpFromText(text).sents)))\n",
    "printElapsedTime(start_time, \"development\")\n",
    "\n",
    "start_time = time.time()\n",
    "for text in evaluation_data['text']:\n",
    "    features['evaluation']['text_len'].append(len(text))\n",
    "    features['evaluation']['exclam_mark_cnt'].append(text.count(\"!\"))\n",
    "    features['evaluation']['question_mark_cnt'].append(text.count(\"?\"))\n",
    "    features['evaluation']['punctuation_cnt'].append(len([char for char in text if char in punctuation]))\n",
    "    features['evaluation']['sentences_cnt'].append(len(list(getNlpFromText(text).sents)))\n",
    "printElapsedTime(start_time, \"development\")\n",
    "\n",
    "# Normalize values\n",
    "start_time = time.time()\n",
    "for feature in features_to_normalize:\n",
    "    values = np.array(features['development'][feature] + features['evaluation'][feature])\n",
    "    z = (values - values.mean())/(values.std())\n",
    "    \n",
    "    features['development'][feature] = list(z[:len(features['development'][feature])])\n",
    "    features['evaluation'][feature] = list(z[len(features['development'][feature]):])\n",
    "printElapsedTime(start_time, 'normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stop_words = get_stop_words('it')\n",
    "stop_words = stopwords.words('italian')\n",
    "words_to_remove_from_stopwords = ['non', 'più', 'sei', 'no'] #['ci', 'contro', 'ma', 'però', 'poco', 'pochi', 'poche', 'poca', 'senza', 'non', 'no', 'più', 'quasi', 'feci']#, 'essere', 'avere', 'sarei', 'saremmo', 'avrei', 'avremmo', 'fossi', 'avessi']\n",
    "words_to_add_to_stopwords = ['essere', 'avere'] #+ list('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~…“”°')\n",
    "replace_before_lemmatization = {\n",
    "    '’': \"'\",\n",
    "    'wi fi': 'wifi',\n",
    "    'wi - fi': 'wifi',\n",
    "    'wi-fi': 'wifi',\n",
    "    \"week-end\": \"weekend\",\n",
    "    'week end': 'weekend',\n",
    "    'check in': 'checkin',\n",
    "    'check out': 'checkout',\n",
    "    'check-in': 'checkin',\n",
    "    'check-out': 'checkout',\n",
    "    'check - in': 'checkin',\n",
    "    'check - out': 'checkout',\n",
    "    '\\n': ' ',\n",
    "    \"a'\": 'à',\n",
    "    \"e'\": 'è',\n",
    "    \"é\": 'è',\n",
    "    \"i'\": 'ì',\n",
    "    \"o'\": 'ò',\n",
    "    \"u'\": 'ù',\n",
    "    \n",
    "    \" €\": \"€\",\n",
    "    \" euro\": \"€\",\n",
    "    \"euro\": \"€\",\n",
    "}\n",
    "\n",
    "# Add words\n",
    "stop_words = [word for word in stop_words if word not in words_to_remove_from_stopwords]\n",
    "stop_words += words_to_add_to_stopwords\n",
    "stop_words = list(set(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "#     strip_accents = None,\n",
    "#     lowercase = True,\n",
    "#     preprocessor = None,\n",
    "    tokenizer = lemmatizer,\n",
    "#     analyzer = 'word', # callable - extract the sequence of features out of the raw, unprocessed input\n",
    "    stop_words = stop_words,\n",
    "    ngram_range = (1, 3),\n",
    "    max_df = 0.45,\n",
    "    min_df = 2,\n",
    "    max_features = 35000, #best: 40000,\n",
    "#     norm = 'l2', # l2\n",
    "#     use_idf = True,\n",
    "#     sublinear_tf = False,\n",
    ")\n",
    "start_time = time.time()\n",
    "tfidf_X = vectorizer.fit_transform(development_data['text'])\n",
    "printElapsedTime(start_time, 'fit-transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot vectorization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_X.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data_to_plot = []\n",
    "for col, term in enumerate(terms):\n",
    "    data_to_plot.append( (term, sums[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data_to_plot, columns=['term','rank']).sort_values('rank', ascending=False)\n",
    "\n",
    "ranking.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_freq = {term: rank for term, rank in zip(ranking['term'], ranking['rank'])}\n",
    "wordcloud = WordCloud().generate_from_frequencies(wc_freq)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_REDUCTION = False\n",
    "TEXT_LENGTH = False#True\n",
    "FIRST_NAMES_CNT = False\n",
    "EXCLAMATION_MARKS_CNT = False#True\n",
    "QUESTION_MARKS_CNT = False#True\n",
    "SENTENCES_CNT = False#True\n",
    "PUNCTUATION_CNT = False#True\n",
    "WORD_TYPES_CNT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "start_time = time.time()\n",
    "X = getFeatures(development_data, tfidf_X, features['development'])\n",
    "y = development_data['class']\n",
    "# y = label_binarize(['pos'], classes=y)[0]\n",
    "\n",
    "printElapsedTime(start_time, \"get all features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "start_time = time.time()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "printElapsedTime(start_time)\n",
    "X = pd.DataFrame(X_norm)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, space_eval, Trials\n",
    "TEXT_LENGTH = False\n",
    "\n",
    "speedy_data = development_data.sample(n=5000)\n",
    "def objective(args):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        strip_accents = None,\n",
    "        lowercase = True,\n",
    "        preprocessor = None,\n",
    "        tokenizer = lemmatizer,\n",
    "        analyzer = 'word', # callable - extract the sequence of features out of the raw, unprocessed input\n",
    "        stop_words = stop_words,\n",
    "        ngram_range = (1, 5),\n",
    "        max_df = args['max_df'],\n",
    "        min_df = args['min_df'],\n",
    "        max_features = int(args['max_features']),\n",
    "        norm = 'l2', # l2\n",
    "        use_idf = True,\n",
    "        sublinear_tf = False,\n",
    "    )\n",
    "    tfidf_X = vectorizer.fit_transform(speedy_data['text'])\n",
    "    X = getFeatures(speedy_data, tfidf_X, features['development'], verbose=False)\n",
    "    y = speedy_data['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    clf = sklearn.svm.LinearSVC(\n",
    "        penalty='l2', # l1, l2\n",
    "        loss='squared_hinge', # hinge, squared_hinge\n",
    "        dual=False, # Prefer dual=False when n_samples > n_features\n",
    "        tol=1e-4,\n",
    "        C=1.0,\n",
    "        multi_class='ovr',\n",
    "        fit_intercept=True,\n",
    "        intercept_scaling=100,\n",
    "        class_weight=None,\n",
    "        verbose=0,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "    \n",
    "    f1_neg = f[0]\n",
    "    f1_pos = f[1]\n",
    "    \n",
    "    weighted_avg_f1 = 0.3*f1_neg + 0.7*f1_pos\n",
    "    \n",
    "    current_best_str = ''\n",
    "#     if weighted_avg_f1 > current_best:\n",
    "#         current_best = weighted_avg_f1\n",
    "#         current_best_str = \"<<<=== CURRENT BEST\"\n",
    "#     print(str(args['max_df']) +\"\\t\" + str(args['min_df']) +\"\\t\" + str(weighted_avg_f1))\n",
    "    \n",
    "    return 1-weighted_avg_f1\n",
    "\n",
    "space = {\n",
    "    'max_df': hp.uniform('max_df', 0.2, 1),\n",
    "    'min_df': hp.uniform('min_df', 0, 0.2),\n",
    "#     'use_idf': hp.choice('use_idf', [True]),\n",
    "    'max_features': hp.quniform('max_features', 100, 50000, 1),\n",
    "}\n",
    "\n",
    "# minimize the objective over the space\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=1000, trials=trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pd_read_csv('trials.csv').drop(columns=['exp_key', 'owner', 'version'])\n",
    "# trials_df['loss'] = trials_df['result']['trials']\n",
    "# trials_df.eval('result[\\'loss\\']')\n",
    "trials_df['time'] = np.nan\n",
    "trials_df['max_features'] = np.nan\n",
    "trials_df['max_df'] = np.nan\n",
    "trials_df['min_df'] = np.nan\n",
    "trials_df['loss'] = np.nan\n",
    "column_time = trials_df.columns.get_loc('time')\n",
    "column_max_features = trials_df.columns.get_loc('max_features')\n",
    "column_max_df = trials_df.columns.get_loc('max_df')\n",
    "column_min_df = trials_df.columns.get_loc('min_df')\n",
    "column_loss = trials_df.columns.get_loc('loss')\n",
    "for index, row in trials_df.iterrows():\n",
    "    trials_df.iloc[index, column_time] = row['refresh_time'] - row['book_time']\n",
    "    trials_df.iloc[index, column_max_features] = row['misc']['vals']['max_features']\n",
    "    trials_df.iloc[index, column_max_df] = row['misc']['vals']['max_df']\n",
    "    trials_df.iloc[index, column_min_df] = row['misc']['vals']['min_df']\n",
    "    try:\n",
    "        trials_df.iloc[index, column_loss] = row['result']['loss']\n",
    "    except:\n",
    "        trials_df.iloc[index, column_loss] = np.nan\n",
    "trials_df = trials_df.drop(columns=['misc', 'result', 'spec', 'state', 'book_time', 'refresh_time']).sort_values(by=['loss'], ascending=True).head(20)\n",
    "trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trials_df['max_df'].quantile(q=0.9))\n",
    "print(trials_df['min_df'].quantile(q=0.5))\n",
    "print(trials_df['max_features'].quantile(q=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn\n",
    "\n",
    "f1_neg = []\n",
    "f1_pos = []\n",
    "for i in range(1):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = False)\n",
    "    printElapsedTime(start_time, 'train_test_split')\n",
    "\n",
    "    # Neighbors\n",
    "#     clf = KNeighborsClassifier();\n",
    "    \n",
    "    # Naive Bias\n",
    "#     clf = GaussianNB()\n",
    "#     clf = MultinomialNB()\n",
    "#     clf = CategoricalNB()\n",
    "#     clf = BernoulliNB()\n",
    "#     clf = ComplementNB()\n",
    "    \n",
    "#     clf = RandomForestClassifier(n_estimators = 10)\n",
    "    \n",
    "#     clf = MLPClassifier(verbose=True, max_iter=10)\n",
    "#     clf = SVC(gamma='auto', verbose=1)\n",
    "    clf = sklearn.svm.LinearSVC(\n",
    "        penalty='l2', # l1, l2\n",
    "        loss='squared_hinge', # hinge, squared_hinge\n",
    "        dual=False, # Prefer dual=False when n_samples > n_features\n",
    "        tol=1e-4,\n",
    "        C=0.4,\n",
    "        multi_class='ovr',\n",
    "        fit_intercept=True,\n",
    "#         intercept_scaling=1,\n",
    "        class_weight='balanced',\n",
    "        verbose=1,\n",
    "#         random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "#     clf = sklearn.linear_model.SGDClassifier()\n",
    "#     clf = LogisticRegression(solver='liblinear', n_jobs=-1)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    printElapsedTime(start_time, 'fit classifier')\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    p, r, f, s = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "    \n",
    "    f1_neg.append(f[0])\n",
    "    f1_pos.append(f[1])\n",
    "    print(f[0], f[1])\n",
    "print(\"Mean F1:\", np.array(f1_neg).mean(), np.array(f1_pos).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\"\"\"COMPUTE ROC CURVE\"\"\"\n",
    "fpr, tpr, threshold = roc_curve(y_true = y_test, y_score = y_test_pred_proba[:, 1], pos_label = 'pos')\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\"\"\"PLOT ROC CURVE\"\"\"\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Youden's J statistic\"\"\"\n",
    "J = tpr - fpr\n",
    "best_threshold = threshold[J.argmax()]\n",
    "\n",
    "y_pred_from_treshold = y_test_pred_proba[:, 1] > best_threshold\n",
    "y_pred_from_treshold = list(map(lambda x: 'pos' if x == True else 'neg', y_pred_from_treshold))\n",
    "\n",
    "p, r, f, s = precision_recall_fscore_support(y_test, y_pred_from_treshold)\n",
    "f1_neg.append(f[0])\n",
    "f1_pos.append(f[1])\n",
    "print(f[0], f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong_X = []\n",
    "for i in range(len(X_test)):\n",
    "    if y_test.iloc[i] != y_test_pred[i]:\n",
    "        wrong_X.append({\n",
    "            'iteration': i,\n",
    "            'id': X_test.index[i],\n",
    "            'y_true': y_test.iloc[i],\n",
    "            'y_pred': y_test_pred[i]\n",
    "        })\n",
    "wrong_X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong_X_curr = wrong_X[9]\n",
    "# wrong_X_curr = {'id': 23858, 'y_true': 'neg', 'y_pred': 'pos'}\n",
    "\n",
    "\n",
    "print(\"TRUE:\", wrong_X_curr['y_true'], \"\\t\\tPREDICTED:\", wrong_X_curr['y_pred'])\n",
    "development_data.iloc[wrong_X_curr['id']]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_weights = pd.DataFrame()\n",
    "features_weights['names'] = vectorizer.get_feature_names()\n",
    "features_weights['weights'] = clf.coef_[0]\n",
    "features_weights['abs_weights'] = abs(clf.coef_[0])\n",
    "features_weights.sort_values(by=['abs_weights'], ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "\n",
    "f_importances(clf.coef_[0], np.array(vectorizer.get_feature_names() + ['text_len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svc_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "clf = MLPClassifier(verbose=True)\n",
    "start_time = time.time()\n",
    "clf.fit(X, y)\n",
    "printElapsedTime(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate unknown data\n",
    "start_time = time.time()\n",
    "eval_tfidf = vectorizer.transform(evaluation_data['text'])\n",
    "printElapsedTime(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_X = getFeatures(evaluation_data, eval_tfidf, features['evaluation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y = clf.predict(eval_X)\n",
    "\n",
    "# Save solution on file\n",
    "with open(\"solution.csv\", \"w+\") as f:\n",
    "    f.seek(0)\n",
    "    f.write(\"Id,Predicted\\n\")\n",
    "    for i, label in enumerate(eval_y):\n",
    "        f.write(f\"{i},{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_RAM = True\n",
    "\n",
    "if SAVE_RAM:\n",
    "    start_time = time.time()\n",
    "    with open('./cache/nlp_documents.p', 'wb') as fp:\n",
    "        pickle.dump(nlp_documents, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    printElapsedTime(start_time)\n",
    "else:\n",
    "    print(\"NOT SAVING!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
